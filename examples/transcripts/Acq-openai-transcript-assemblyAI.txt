A: I will say, david, I would love to have Nvidia's full production team every episode. It was nice not having to worry about turning the cameras on and off and making sure that nothing bad happened myself while we were recording this.
B: Yeah, just the gear. I mean, the drives that came out of the camera.
A: All right. Red cameras for the home studio starting next episode.
B: Yeah.
C: Great.
A: All right, let's do it.
C: Who got the truth? Is it you?
A: Is it you?
C: Is it you? Who got the truth now?
A: Is it you? Is it you? Is it you?
C: Sit me down. Say it straight. Another story on the way. Who got the truth?
A: Welcome to this episode of Acquired, the podcast about great technology companies and the stories and playbooks behind them. I'm Ben Gilbert.
B: I'm David Rosenthal.
A: And we are your hosts, listeners, just so we don't bury the lead, this episode was insanely cool for David and I. Yeah. After researching Nvidia for something like 500 hours over the last two years, we flew down to Nvidia headquarters to sit down with Jensen himself. And Jensen, of course, is the founder and CEO of Nvidia, the company powering this whole AI explosion. At the time of recording, Nvidia is worth $1.1 trillion and is the 6th most valuable company in the entire world. And right now is a crucible moment for the company. Expectations are set high. I mean, sky high. They have about the most impressive strategic position and lead against their competitors of any company that we've ever studied. But here's the question that everyone is wondering. Will Nvidia's insane prosperity continue for years to come? Is AI going to be the next trillion dollar technology wave? How sure are we of that? And if so, can Nvidia actually maintain their ridiculous dominance as this market comes to take shape? So Jensen takes us down memory lane with stories of how they went from graphics to the data center to AI, how they survived multiple near death experiences. He also has plenty of advice for founders, and he shared an emotional side to the founder journey toward the end of the episode.
B: Yeah, I got new perspective on the company and on him as a founder and a leader just from doing this. Despite. We thought we knew everything before we came in advance, and it turned out we didn't.
A: Turns out the protagonist actually knows more.
B: Yes.
A: All right, well, listeners, join the slack. There is incredible discussion of everything about this company, AI, the whole ecosystem, and a bunch of other episodes that we've done recently going on in there right now. So that is acquired FM Slash slack. We would love to see you. And without further ado, this show is not investment advice. David and I may have investments in the companies we discuss, and this show is for informational and entertainment purposes only. Onto Jensen. So Jensen, this is acquired. So we want to start with story time. So we want to wind the clock all the way back to, I believe it was 1997. You're getting ready to ship the Riva 128, which is one of the largest graphics chips ever created in the history of computing. It is the first fully 3d accelerated graphics pipeline for a computer. And you guys have six months of cash left. And so you decide to do the entire testing in simulation, rather than ever receiving a physical prototype. You commission the production run site unseen with the rest of the company's money. So you're betting it all right here on the Riva 128, it comes back. And of the 32 directx blend modes, it supports eight of them. And you have to convince the market to buy it. And you got to convince developers not to use anything but those eight blend modes. Walk us through what, that the other.
C: 24 weren't that important.
B: Okay, so wait, wait. First question. Was that the plan all along? Like, when did you realize?
C: I realized I didn't learn about it until it was too late. We should have implemented all 32, but we built what we built, and so we had to make the best of it. That was really an extraordinary time. Remember, revo 120 was MV three, MV one, and MV two were based on forward texture mapping. No triangles, but curves. And it tessellated the curves. And because we were rendering higher level objects, we essentially avoided using z buffers. And we thought that that was going to be a good rendering approach. And turns out to have been completely the wrong answer. And so what Revo run 28 was, was a reset of our company. Now, remember, at the time that we started the company in 1993, we were the only consumer 3d graphics company ever created. And we were focused on transforming the pc into an accelerated pc because at the time, Windows was really a software rendered system. And so anyways, Riva 128 was a reset of our company because by the time that we realized we had gone down the wrong road. Microsoft had already rolled out DirectX. It was fundamentally incompatible with Nvidia's architecture. 30 competitors have already shown up, even though we were the first company at the time that we were founded. So the world was a completely different place. The question about what to do as a company strategy at that point, I would have said that we made a whole bunch of wrong decisions. But on that day that mattered, we made a sequence of extraordinarily good decisions. And that time, 1997, was probably Nvidia's best moment. And the reason for that was, our backs were up against the wall, we were running out of time, we were running out of money for a lot of employees, running out of hope. And the question is, what do we do? Well, the first thing that we did was we decided that, look, DirectX is now here. We're not going to fight it. Let's go figure out a way to build the best thing in the world for it. Revo 128 is the world's first fully accelerated hardware accelerated pipeline for rendering three D. And so the transform, the projection, every single element, all the way down to the frame buffer, was completely hardware accelerated. We implemented a texture cache. We took the bus limit, the frame buffer limit, to as big as physics could afford at the time. We made the biggest chip that anybody had ever imagined building. We used the fastest memories. Basically, if we built that chip, there could be nothing that could be faster. And we also chose a cost point that is substantially higher than the highest price that we think that any of our competitors would be willing to go if we built it. Right. We accelerated everything. We implement everything in DirectX that we knew of, and we build it as large as we possibly could, then obviously, nobody can build something faster than that today.
B: In a way, you kind of do that here at Nvidia, too. You were a consumer products company back then, right? It was end consumers who were going to have to pay the money to buy this.
C: That's right. But we observed that there was a segment of the market where people were. Because at the time, the pc industry was still coming up, and it wasn't good enough, everybody was clamoring for the next fastest thing. If your performance was ten times higher this year than what was available, there's a whole large market of enthusiasts who we believe would have gone after it. And we were absolutely right that the pc industry had a substantially large enthusiast market that would buy the best of everything. To this day, it remains true. And for certain segments of the market, where the technology is never good enough, like 3d graphics, and we chose the right technology. 3d graphics is never good enough. And we call it back then 3d gives us sustainable technology opportunity, because it's never good enough, and so your technology can keep getting better. We chose that. We also made the decision to use this technology called emulation. There was a company called Iqos, and on the day that I called them, they were just shutting the company down because they had no customers. And I said, hey, look, I'll buy what you have inventory and no promises are necessary. And the reason why we needed that emulator is because if you figure out how much money that we have, if we taped out a chip and we got it back from the fab and we started working on our software, by the time that we found all the bugs, because we did the software, then we taped out a chip again, well, we would have been out of business already. And so I knew.
B: I knew your competitors would have caught up.
C: Well, not to mention we would have been out of business.
B: Who cares?
C: Exactly. So if you're going to be out of business anyways, that plan obviously wasn't the plan. The plan that companies normally go through, which is build the chip, write the software, fix the bugs, tape out the new chip, so on and so forth, that method wasn't going to work. So the question is, if we only had six months and you get to tape out just one time, then obviously you're going to tape out a perfect chip. So I remember having conversation with our leaders, and they said, but Jensen, how do you know it's going to be perfect? I said, I know it's going to be perfect, because if it's not, we'll be out of business. And so let's make it perfect. We get one shot. We essentially virtually prototyped the chip by buying this emulator. And Dwight and the software team wrote our software, the entire stack, and ran it on this emulator and just sat in the lab waiting for windows to paint, you know, and when 60 seconds.
B: For a frame or something like that.
C: Easily, I actually think that was an hour per frame, something like that. And so we would just sit there and watch it paint. And so on the day that we decided to tape out, I assumed that the chip was perfect and everything that we could have tested, we tested in advance and told everybody, this is it. We're going to tape out the chip. It's going to be perfect. Well, if you're gonna tape out a chip and you know it's perfect, then what else would you do? That's actually the good question. If you knew that you hit enter, you take that, a chip, and you knew it was gonna be perfect, then what else would you do? Well, the answer, obviously go to production and marketing blitz. Yeah, yeah.
A: And developer audience kick everything off.
C: Kick everything off because you got a perfect chip. And so we got in our head that we have a perfect chip.
B: How much of this was you, and how much of this was like your co founders, the rest of the company, the board? Was everybody telling you you were crazy?
C: No, everybody was clear we had no shot. Not doing it would be crazy, because.
B: Otherwise, you might as well go home.
C: You're gonna be out of business anyways. So anything aside from that is crazy. So it seemed like a fairly logical thing, and quite frankly, right now I'm describing it, you're probably thinking, yeah, it's pretty sensible.
B: Well, it worked.
C: Yeah. And so we take that out and went directly to production.
A: So is the lesson for founders out there, when you have conviction on something like the Revo 128 or Cuda, go bet the company on it. And this keeps working for you. So it seems like your lesson learned from this is, yes, keep pushing all the chips in, because so far, it's worked every time.
C: No.
B: How do you think about that?
C: No, no. When you push your chips in, I know it's going to work. Notice we assume that we taped out a perfect chip. The reason why we taped out a perfect chip is because we emulated the whole chip before we taped it out. We developed the entire software stack. We ran QA on all the drivers and all the software. We ran all the games we had. We ran every VGA application we had. And so when you push your chips in, what you're really doing is when you bet the farm, you're saying, I'm gonna take everything in the future, all the risky things, and I pull it in advance. And that is probably the lesson. And to this day, everything that we can prefetch, everything in the future that we can simulate, today, we prefetch it.
B: We talk about this a lot. We were just talking about this on our Costco episode. You want to push your chips in when you know it's going to work.
A: So every time we see you make a bet, the company move, you've already simulated it, you know?
C: Yeah, yeah, yeah.
A: Do you feel like that was the case with Cuda?
C: Yeah. In fact, before there was Cuda, there was a CG. We were already playing with the concept of how do we create an abstraction layer above our chip that is expressible in a higher level language and higher level expression? And how can we use our GPU for things like CT reconstruction, image processing? We were already down that path. There were some positive feedback and some intuitive positive feedback that we think that general purpose computing could be possible. If you just looked at the pipeline of a programmable shader. It is a processor and is highly parallel, and it is massively threaded, and it is the only processor in the world that does that. There were a lot of characteristics about programmable shading that would suggest that CUDA has a great opportunity to succeed.
A: That is true if there was a large market of machine learning practitioners who would eventually show up and want to do all this great scientific computing and accelerated computing. But at the time when you were starting to invest what is now something like 10,000 person years in building that platform, did you ever feel like, oh, man, we might have invested ahead of the demand for machine learning since we're like a decade before the whole world is realizing it?
C: I guess, yes and no. When we saw deep learning, when we saw Alexnet and realized its incredible effectiveness in computer vision, we had the good sense, if you will, to go back to first principles and ask, what is it about this thing that made it so successful? When a new software technology, a new algorithm, comes along and somehow leapfrogs 30 years of computer vision work, you have to take a step back and ask yourself, but why? And fundamentally, is it scalable? And if it's scalable, what other problems can it solve? And there were several observations that we made. The first observation, of course, is that if you have a whole lot of example data, you could teach this function to make predictions. Well, what we basically done is discovered a universal function approximator, because the dimensionality could be as high as you want it to be, and because each layer is trained one layer at a time, there's no reason why you can't make very, very deep neural networks. So now you just reason your way through, right? Okay, so now I go back to twelve years ago, you could just imagine the reasoning I'm going through in my head, that we've discovered a universal function approximator. In fact, we might have discovered with a couple more technologies, a universal computer.
B: That'S paying attention to the imagenet competition whenever you're leading up to this.
C: Yeah, yeah. And the reason for that is because we were already working on computer vision at the time, and we were trying to get CUDA to be a good computer vision system, or most of the algorithms that were created for computer vision aren't a good fit for CUDA. And so what, we're sitting there trying to figure it out, all of a sudden Alexnet shows up. And so that was incredibly intriguing. It's so effective that it makes you take a step back and ask yourself, why is that happening? So by the time that you reason your way through this, you go, well, what are the kind of problems in a world where a universal function approximator can solve? Right. Well, we know that most of our algorithms start from principled sciences. Okay, you want to understand the causality. And from the causality, you create a simulation algorithm that allows us to scale, well, for a lot of problems. We kind of don't care about the causality. We just care about the predictability of it. Like, do I really care for what reason you prefer this toothpaste over that? I don't really care the causality. I just want to know that this is the one you would have predicted. Do I really care that the fundamental cause of somebody who buys a hot dog buys ketchup and mustard, it doesn't really matter. It only matters that I can predict it. It applies to predicting movies, predicting music. It applies to predicting, quite frankly, weather. We understand thermodynamics, we understand radiation from the sun, we understand cloud effects, we understand oceanic effects. We understand all these different things. We just want to know whether we should wear sweater or not. Is that right? Yep. And so causality for a lot of problems in the world doesn't matter. We just want to emulate the system and predict the outcome.
A: And it can be an incredibly lucrative market if you can predict what the next best performing feed item to serve into a social media feed. Turns out that's a huge.
B: I love the examples you pulled. Toothpaste, ketchup, music, movies.
C: When you realize this, you realize, hang on a second. A universal functional approximator, a machine learning system, something that learns from examples, could have tremendous opportunities because just the number of applications is quite enormous. And everything from, obviously, we just talked about commerce all the way to science. And so you realize that maybe this could affect a very large part of the world's industries. Almost every piece of software in the world would eventually be programmed this way. And if that's the case, then how you build a computer and how you build a chip, in fact, can be completely changed. And realizing that the rest of it just comes with, do you have the courage to put your chips behind it?
B: So that's where we are today, and that's where Nvidia is today. But I'm curious in that there's a couple years after Alexnet, and this is when Ben and I were getting into the technology industry and the venture industry ourselves.
A: I started at Microsoft in 2012. So right after Alexnet, but before anyone was talking about machine learning and even the mainstream engineering community, there were those.
B: Couple of years there where to a lot of the rest of the world, these looked like science projects.
C: Yeah.
B: The technology companies here in Silicon Valley, particularly the social media companies, they were just realizing huge economic value out of this. The Googles, the Facebooks, the Netflixs, etcetera. And obviously that led to lots of things, including OpenAI a couple years later. But during those couple years, when you saw just that huge economic value unlock here in Silicon Valley, how are you feeling during those times?
C: The first thought was, of course, reasoning about how we should change our computing stack. The second thought is, where can we find earliest possibilities of use? If we were to go build this computer, what would people use it to do? And we were fortunate that working with the world's universities and researchers was innate in our company, because we were already working on CuDA, and CuDA's early adopters were researchers, because we democratize supercomputing. Cuda is not just used, as you know, for AI. CudA is used for almost all fields of science, everything from molecular dynamics to imaging, CT reconstruction, to seismic processing, to weather simulations, quantum chemistry. The list goes on, right? And so the number of applications of CUDA in research was very high. And so when the time came and we realized that deep learning could be really interesting, it was natural for us to go back to the researchers and find every single AI researcher on the planet and say, how can we help you advance your work? And that included Yann Lecun and Andrew Ng and Jeff Hinton. And that's how I met all these people. And I used to go to all the AI conferences, and that's where I met Ilya Suskever there for the first time. And so it was really about at that point, what are the systems that we can build and the software stacks we can build to help you be more successful to advance the research? Because at the time it looked like a toy. But we had confidence that even Gan, the first time I met Goodfellow, the Gan was like 32 by 32, and it was just a blurry image of a cat, but how far can it go? And so we believed in it. We believed that one, you could scale deep learning, because obviously it's trained layer by layer, and you could make the datasets larger and you could make the models larger. And we believe that if you made that larger and larger, it would get better, better and better, kind of sensible. And I think the discussions and the engagements with the researchers was the exact positive feedback system that we needed. I would go back to research, that's where it all happened.
B: When OpenAI was founded in 2015, I mean, that was such an important moment. That's obvious today, now. But at the time, I think most people, even people in tech, were like, what is this? Were you involved in it at all? Because you were so connected to the researchers, to Ilia taking that talent out of Google and Facebook, to be blunt. But reseeding the research community and opening it up was such an important moment. Were you involved in it at all?
C: I wasn't involved in the founding of it, but I knew a lot of the people there. And Elon, of course I knew, and Peter Beale was there, and Ilya was there. We have some great employees today that were there in the beginning, and I knew that they needed this amazing computer that we were building. And we were building the first version of the DGX, which today, when you see a hopper, it's 70 pounds, 35,000 parts, 10,000 amps. But DGX, the first version that we built, was used internally, and I delivered the first one to OpenAI. That was a fun day. But most of our success was aligned around in the beginning, just about helping the researchers get to the next level. I knew it wasn't very useful in its current state, but I also believe that in a few clicks, it could be really remarkable. And that belief system came from the interactions with all these amazing researchers, and it came from just seeing the incremental progress. At first, the papers were coming out every three months, and then, then papers today are coming out every day. You could just monitor the archive papers. And I took an interest in learning about the progress of deep learning, and to the best of my ability, read these papers, and you could just see the progress happening in real time, exponentially in real time.
A: It even seems like within the industry, from some researchers we spoke with, it seemed like no one predicted how useful language models would become. When you just increased the size of the models, they thought, oh, there has to be some algorithmic change that needs to happen. But once you cross that 10 billion parameter mark, and certainly once you cross the 100 billion, they just magically got much more accurate, much more useful, much more lifelike. Were you shocked by that, the first time you saw a truly large language model? And do you remember that feeling?
C: Well, my first feeling about the language model was how clever it was to just mask out words and make it predict the next word. It's self supervised learning at its best. We have all this text. I know what the answer is. I'll just make you guess it. And so my first impression of Bert was really how clever it was. And now the question is, how can you scale that? The first observation on almost everything is interesting, and then try to understand intuitively why it works. And then the next step, of course, is from first principles. How would you extrapolate that. And so obviously we knew that Bert was going to be a lot larger. Now, one of the things about these language models is it's encoding information, isn't that right? It's compressing information. And so within the world's languages and text, there's a fair amount of reasoning that's encoded in it. We describe a lot of reasoning things. And so if you were to say that few step reasoning is somehow learnable from just reading things, I wouldn't be surprised. For a lot of us, we get our common sense and we get our reasoning ability by reading. And so why wouldn't a machine learning model also learn some of the reasoning capabilities from that? And from reasoning capabilities you could have emergent capabilities. Emergent abilities are consistent with intuitively from reasoning. And so some of it could be predictable. But still, it's still amazing. The fact that it's sensible doesn't make it any less amazing. I could visualize literally the entire computer and all the modules in a self driving car. And the fact that it's still keeping lanes makes me insanely happy.
A: I even remember that from my first operating systems class in college when I finally figured out all the way from programming language to the electrical engineering classes bridged in the middle by that Os class, I'm like, oh, I think I understand how the Von Neumann computer works. Soup to nuts. And it's still a miracle.
C: Yeah, yeah, yeah. Exactly. Yeah, yeah. When you put it all together, it's still a miracle. Yeah.
A: Now is a great time to talk about one of our favorite companies, Statsig. And we have some tech history for you.
B: Yes. So in our Nvidia part three episode, we talked about how the AI research teams at Google and Facebook drove incredible business outcomes with cutting edge ML models. And these models powered features like the Facebook newsfeed, Google Ads, and the YouTube next video recommendation, in the process transforming Google and Facebook into the juggernauts that we know today. And while we talked all about the research, we didn't touch on how these models were actually deployed.
A: Yeah. The most common way to deploy new models was through experimentation a b testing. When the research team created a new model product engineers would deploy the model to a subset of users and measure the impact of the model on core product metrics. Great experimentation tools transformed the machine learning development process. They de risked releases. Since each model could be released to a small set of users, they sped up release cycles. Researchers could suddenly get quick feedback from real user data. And most importantly, they created a pragmatic, data driven culture. Since researchers were rewarded for driving actual product improvements. And over time, these experimentation tools gave Facebook and Google a huge edge because they really became a requirement for leading ML teams.
C: Yep.
B: So now you're probably thinking, well, that's great for Facebook and Google, but my team can't build out our own internal experimentation platform. Well, you don't have to, thanks to Statsig. So Statsig was literally founded by ex Facebook engineers who did all this. They've built a best in class experimentation feature, flagging and product analytics platform that's available to anyone. And surprise, surprise, a ton of AI companies are now using Statsig to improve and deploy their models, including OpenAI and anthropic.
C: Yep.
A: So whether you're building with AI or not, Statsig can help your team ship faster and make better data driven product decisions. They have a very generous free tier and a special program for venture backed companies, simple pricing for enterprises, and no seat based fees. If you're in the acquired community, there's a special offer. You get 5 million free events a month and white glove onboarding support. So visit statsig.com acquired and get started on your data driven journey. We have some questions we want to ask you. Some are cultural about Nvidia, but others are generalizable to company building broadly. And the first one that we wanted to ask is, we've heard that you have 40 plus direct reports and that this chart, it works a lot differently than a traditional company chart. Do you think there's something special about Nvidia that makes you able to have so many direct reports, not worry about coddling or focusing on career growth of your executives? And you're like, no, you're just here to do your fricking best work. And the most important thing in the world. Now go. A, is that correct? And b, is there something special about Nvidia that enables that?
C: I don't think it's something special about Nvidia. I think that we had the courage to build a system like this. Nvidia is not built like a military. It's not built like the armed forces, where you have generals and colonels. We're not set up like that. We're not set up in a command and control and information distribution system. From the top down, we're really built much more like a computing stack and a computing stack. The lowest layer is our architecture, and then there's our chip, and then there's our software. And on top of it, there are all these different modules. And each one of these layers of modules are people. And so the architecture of the company, to me, is a computer with a computing stack with people managing different parts of the system and who reports to whom. Your title is not related to anywhere you are in the stack. It just happens to be who is the best at running that module, on that function, on that layer, is in charge, and that person is the pilot in command. And so that's one characteristic.
B: Have you always thought about the company this way, even from the earliest days?
C: Yeah, pretty much, yeah. And the reason for that is because your organization should be the architecture of the machinery of building the product. Right. That's what a company is. And yet everybody's company look exactly the same, but they all build different things. How does that make any sense? Do you see what I'm saying?
B: Yeah.
C: How you make fried chicken versus how you flip burgers versus how you make chinese fried rice, it's different. And so why would the machinery, why would the process be exactly the same? And so it's not sensible to me that if you look@the.org charts of most companies, it all kind of looks like this. And then you have one group that's for a business, and you have another for another business, you have another for another business, and they're all supposedly autonomous. And so none of that stuff makes any sense to me. It just depends on what is it that we're trying to build and what is the architecture of the company that best suits to go build it. So that's number one in terms of information system. And how do you enable collaboration? We kind of wired up like a neural network. And the way that we say is that there's a phrase in the company called mission is the boss. And so we figure out what is the mission of what is the mission, and we go wire up the best skills and the best teams and the best resources to achieve that mission. And it cuts across the entire organization in a way that doesn't make any sense, but it looks like a little bit like a neural network.
B: And when you say mission, do you mean mission like Nvidia's mission is Dale Hopper?
C: Yeah.
B: Okay, so it's not like further accelerated computing. It's like we're shipping DGX cloud, build.
C: Hopper, or somebody else's. Build a system for Hopper, somebody is build Cuda for Hopper, somebody's job is build Cudnn for Cuda. For Hopper, somebody's job is the mission. Right. So your mission is to do something.
A: What are the tradeoffs associated with that versus the traditional structure?
C: The downside is the pressure on the leaders is fairly high, and the reason for that is because in a command and control system, the person who you reports to has more power than you. And the reason why they have more power than you is because they're closer to the source of information than you are. In our company, the information is disseminated fairly quickly to a lot of different people, and usually at a team level. So, for example, just now, I was in our robotics meeting, and we're talking about certain things, and we're making some decisions. And there are new college grads in a room. There's three vice presidents in the room. There's two e staffs in a room. And at the moment that we decided together, we reasoned through some stuff, we made a decision. Everybody heard it exactly the same time. So nobody has more power than anybody else. Does that make sense? The new college grad learned at exactly the same time as the e staff. And so the executive staff and the leaders that work for me and myself, you earn the right to have your job based on your ability to reason through problems and helping other people succeed. And it's not because you have some privileged information that I knew the answer was 3.7, and only I knew. Everybody knew.
B: When we did our most recent episode on video, part three that we just released, we sort of did this thought exercise. Especially over the last couple years, your product shipping cycle has been very impressive, especially given the level of technology that you are working with and the difficulty of this all. We sort of said, could you imagine Apple shipping two iPhones a year?
A: And we said that for illustrative purposes.
B: For illustrative purposes, not to pick on.
A: Apple or whatever, a large tech company shipping two flagship products or their flagship product twice per year.
B: Yeah, or two WWDCs a year.
A: There seems to be something.
B: You can't really imagine that, whereas that happens here. Are there other companies, either current or historically, that you look up to, admire, maybe took some of this inspiration from?
C: In the last 30 years, I've read my fair share of business books. And as in everything you read, you're supposed to, first of all, enjoy it, right? Enjoy it, be inspired by it, but not to adopt it. That's not the whole point of these books. The whole point of these books is to share their experiences. And you're supposed to ask, what does it mean to me in my world, and what does it mean to me in the context of what I'm going through? What does this mean to me and the environment that I'm in and what does this mean to me and what I'm trying to achieve. And what does this mean to Nvidia and the age of our company and the capabilities of our company? And so you're supposed to ask yourself, what does it mean to you? And then from that point, being informed by all these different things that we're learning, we're supposed to come up with our own strategies. What I just described is kind of how I go about everything. You're supposed to be inspired and learn from everybody else, and the education's free. When somebody talks about a new product, you're supposed to go listen to it. You're not supposed to ignore it. You're supposed to go learn from it. And it could be a competitor, it could be adjacent industry, it could be nothing to do with us. The more we learn from whats happening out in the world, the better. But then youre supposed to come back and ask yourself, what does this mean to us?
B: Yeah, you dont just want to imitate them.
C: Thats right.
B: I love this tee up of learning, but not imitating and learning from a wide array of sources. Theres this sort of unbelievable third element, I think, to what Nvidia has become today. That's the data center. It's certainly not obvious. I can't reason from Alexnet and your engagement with the research community and social media feed recommenders to you deciding and the company deciding, all in, we're going to go on a five year all in journey on the data center. How did that happen?
C: Our journey to the data center happened, I would say, almost 17 years ago. I'm always being asked what are the challenges that the company could see someday? And I've always felt that the fact that Nvidia's technology is plugged into a computer and that computer has to sit next to you because it has to be connected to a monitor that will limit our opportunity someday because there are only so many desktop PCs that plug a GPU into and there's only so many crts in the time LCD's that we could possibly drive. So the question is, wouldn't it be amazing if our computer doesn't have to be connected to the viewing device, that the separation of it made it possible for us to compute somewhere else? And one of our engineers came and showed it to me one day and it was really capturing the frame buffer, encoding it into video and streaming it to a receiver device, separating computing from.
A: The viewing in many ways. Cloud gaming 18 years earlier.
C: In fact, that was when we started GFN. We knew that GFN was going to be a journey that would take a long time, because you're fighting all kinds of problems, including the speed of light.
A: And latency everywhere you look.
C: That's right.
B: For listening to GFN. GeForce now.
C: GeForce now. Yeah, yeah, GeForce now.
B: And we've been working on your first cloud product.
C: That's right. And look at GeForce now was Nvidia's first data center product. And our second data center product was remote graphics, putting our GPU's in the world's enterprise data centers, which then led us to our third product, which combined Cuda plus our GPU, which became a supercomputer, which then worked towards more and more and more. The reason why it's so important is because the disconnection between where Nvidia's computing is done versus where it's enjoyed. If you can separate that, your market opportunity explodes. And it was completely true. And so we're no longer limited by the physical constraints of the desktop pc sitting by your desk, and we're not limited by one gpu per person. And so it doesn't matter where it is anymore. And so that was really the great observation.
A: It's a good reminder. The data center segment of Nvidia's business, to me, has become synonymous with how is AI going? And that's a false equivalence. And it's interesting that you were only this ready to sort of explode in AI in the data center because you had three plus previous products where you learned how to build data center computing.
C: Exactly.
A: Even though those markets weren't these gigantic world changing technology shifts the way that AI is. That's how you learned.
C: Yeah, that's right. You want to pave the way to future opportunities. You can't wait until the opportunity is sitting in front of you for you to reach out for it. And so you have to anticipate our job as CEO's to look around corners and to anticipate where will opportunities be someday. And even if I'm not exactly sure what and when, how do I position the company to be near it, to be just standing kind of near under the tree, and we can do a diving catch when the apple falls. You guys know what I'm saying? Yeah, but you've got to be close enough to do the diving catch.
B: Rewind to 2015 and OpenAI. If you hadn't been laying this groundwork in the data center, you wouldn't be powering OpenAI right now.
C: Yeah, but the idea that computing would be mostly done away from the viewing device, that the vast majority of computing would be done away from the computer itself, that insight was good. In fact, cloud computing, everything about today's computing is about separation of that. And by putting it in a data center, we can overcome this latency problem. Meaning you're not going to overcome speed of light. Speed of light, end to end is only 120 milliseconds or something like that. It's not that long.
A: From a data center to an Internet.
C: Anywhere on the planet. Yeah.
A: Oh, I see. Literally across the planet.
C: Yeah. Right. So if you could solve that problem approximately, something like that, I forget the number, but 70 milliseconds, 100 milliseconds, but it's not that long. And so my point is, if you could remove the obstacles everywhere else, then speed of light should be perfectly fine, and you could build data centers as large you like, and you could do amazing things. And this little tiny device that we use as a computer or your tv as a computer, whatever computer, they can all instantly become amazing. And so that insight 15 years ago was a good one.
A: So speaking of the speed of light, infiniband, David's begging me to go here.
B: I said the same thought.
A: You totally saw that Infiniband would be way more useful way sooner than anyone else realized. Acquiring Mellanox, I think you uniquely saw that this was required to train large language models, and you were super aggressive in acquiring that company. Why did you see that when no one else saw that?
C: Well, there are several reasons for that. First, if you want to be a data center company, building the processing chip isn't the way to do it. A data center is distinguished from a desktop computer versus a cell phone, not by the processor in it. A desktop computer in a data center uses the same cpu's, uses the same GPU's, apparently. Right, very close. And so it's not the chip, it's not the processing chip that describes it, but it's the networking of it. It's the infrastructure of it. It's how the computing is distributed, how security is provided, how networking is done, so on and so forth. And so those characteristics are associated with Mellanox, not Nvidia. And so the day that I concluded that really, Nvidia wants to be, you know, build computers of the future, and computers of the future are going to be data centers embodied in data centers, then we want to be data center oriented company, then we really need to get into networking. And so that was one. The second thing is observation that whereas cloud computing started in hyperscale, which is about taking commodity components, a lot of users, and virtualizing many users on top of one computer, AI is really about distributed computing, where one job, one training job is orchestrated across millions of processors. And so it's the inverse of hyperscale, almost. And the way that you design a hyperscale computer with. With off the shelf commodity Ethernet, which is just fine for Hadoop, it's just fine for search queries, it's just fine for all of those things.
A: But now, when you're sharding a model across California.
C: No, you're sharding a model across. Right. And so that observation says that the type of networking you want to do is not exactly Ethernet. And the way that we do networking for supercomputing is really quite ideal. And so the combination of those two ideas convinced me that Mellanox is absolutely the right company because they're the world's leading high performance networking company. And we worked with them in so many different areas in high performance computing already. Plus, I really liked the people. The Israel team is world class. We have some 3200 people there now, and it was one of the best strategic decisions I'd ever made.
B: When we were researching, particularly part three of our Nvidia series, we talked to a lot of people, and many people told us the Mellanox acquisition is one of, if not the best of all time by any technology company.
C: I think so, too. Yeah. And it's so disconnected from the work that we normally do. It was surprising to everybody.
A: But framed this way, you were standing near where the action was, so you could figure out as soon as that apple sort of becomes available to purchase, like, oh, llms are about to blow up. I'm gonna need that. Everyone's gonna need that. I think I know that before anyone else does.
C: Yeah, you wanna position yourself near opportunities. You don't have to be that perfect. You know, you want to position yourself near the tree. And even if you don't catch the apple before it hits the ground, so long as you're the first one to pick it up, you want to position yourself close to the opportunities. And so that's kind of a lot of my work, is positioning the company near opportunities, having the company, having the skills to monetize each one of the steps along the way so that we can be sustainable.
A: What you just said reminds me of a great aphorism from Buffett and Munger, which is, it's better to be approximately right than exactly wrong.
C: Yeah, there you go. Yeah, that's a good one. It's a good one. That's a good one to live by. Yeah.
A: All right, listeners, we are here to tell you about a company that literally couldn't be more perfect for this episode. Crusoe.
B: Yes, Crusoe, as you know by now, is a cloud provider built specifically for AI workloads and powered by clean energy. And Nvidia is a major partner of Crusoe. Their data centers are filled with a as you probably know, with the rising demand for AI, there's been a huge surge in the need for high performing GPU's, leading to a noticeable scarcity of Nvidia GPU's in the market. Crusoe has been ahead of the curve and is among the first cloud providers to offer Nvidia's h scale. They have a very straightforward strategy, create the best AI cloud solution for customers using the very best GPU hardware on the market that customers ask for, like Nvidia, and invest heavily in an optimized cloud software stack.
C: Yep.
A: To illustrate, they already have several customers already running large scale generative AI workloads on clusters of Nvidia H 100 GPU's, which are interconnected with 3200 gigabit Infiniband and leveraging Crusoe's network attached block storage solution. And because their cloud is run on wasted, stranded or clean energy, they can provide significantly better performance per dollar than traditional cloud providers.
C: Yep.
B: Ultimately, this results in a huge win win. They take what is otherwise a huge amount of energy waste that causes environmental harm and use it to power massive AI workloads. And it's worth noting that through their operations, Crusoe is actually reducing more emissions than they would generate. In fact, in 2022, Crusoe captured over 4 billion cubic feet of gas, which led to the avoidance of approximately 500,000 metric tons of CO2 emissions. That's equivalent to taking about 160,000 cars off the road.
A: Amazing. If you, your company, or your portfolio companies could use lower cost and more performant infrastructure for your AI workloads, go to crusoecloud.com acquired. That's Crusoe cloud.com acquired. Or click the link in the show notes I want to move away from Nvidia if you're okay with it, and ask you some questions, since we have a lot of founders that listen to this show sort of advice for company building. The first one is when you're starting a startup in the earliest days, your biggest competitor is you don't make anything people want, like your company's likely to die non consumption, just because people don't actually care as much as you do.
C: About what they're doing.
A: In the later days, you actually have to be very thoughtful about competitive strategy. I'm curious, what would be your advice to companies that have product market fit that are starting to grow? They're in interesting, growing markets. Where should they look for competition and how should they handle it?
C: Well, there are all kinds of ways to think about competition. We prefer to position ourselves in a way that serves a need that usually hasn't emerged.
B: I've heard you or others in Nvidia, I think, use the phrase zero billion dollar market.
C: That's exactly right. Yeah. It's our way of saying there's no market yet, but we believe there will be one. And usually when you're positioned there, everybody's trying to figure out, why are you here? Right. Because when we first got into automotive, because we believe that in the future, the car is going to be largely software. And if it's going to be largely software, a really incredible computer is necessary. And so when we positioned ourselves there, most people, I still remember one of the ctos told me, you know what, cars cannot tolerate the blue screen of death. And I said, I don't think anybody can tolerate that. But it doesn't change the fact that someday every car will be a software defined car. And I think 15 years later, we're largely right. So oftentimes there's non consumption, and we like to navigate our company there. And by doing that, by the time that the market emerges, it's very likely there aren't that many competitors shaped that way. We were early in pc gaming, and today Nvidia is very large in pc gaming. We reimagined what a design workstation would be like. And today, just about every workstation on the planet uses Nvidia's technology. We reimagined how supercomputing ought to be done and who should benefit from supercomputing that we would democratize it. And look, today, Nvidia's and accelerated computing is quite large. And we reimagined how software would be done, and today it's called machine learning and how computing would be done. We call it AI. And so we reimagined these kind of things, try to do that about a decade in advance. And so we spent about a decade in zero billion dollar markets. And today I spent a lot of time on omniverse. And omniverse is a classic example of a zero billion dollar business.
A: There's like 40 customers now.
B: Hey, Amazon, BMW.
C: Yeah, it's cool. It's cool.
A: So let's say you do get this great ten year lead, but then other people figure it out. And you got people nipping at your heels. What are some structural things that someone who's building a business can do to sort of stay ahead? And you can just keep your pedal to the metal and say, we're going to outwork them and we're going to be smarter. And like that works to some extent. Those are tactics. What strategically can you do to make sure that you can maintain that lead?
C: Oftentimes, if you created the market, you ended up having what people describe as moats. Because if you build your product right and it's enabled an entire ecosystem around you to help serve that end market, you've essentially created a platform. Sometimes it's a. It's a product based platform, sometimes it's a service based platform, sometimes a technology based platform. But if you were early there and you were mindful about helping the ecosystem succeed with you, you ended up having this network of networks and all these developers and all these customers who are built around you, and that network is essentially your moat. And so I don't love thinking about it in the context of a moat. And the reason for that is because you're now focused on building stuff around your castle. I tend to like thinking about things in the context of building a network, and that network is about enabling other people to enjoy the success of the final market, that you're not the only company that enjoys it, but you're enjoying it with a whole bunch of other people, including me.
B: I'm so glad you brought this up because I wanted to ask you, in my mind at least, and sounds like in yours too, Nvidia is absolutely a platform company, of which there are very few meaningful platform companies in the world. I think it's also fair to say that when you started, for the first few years, you were a technology company and not a platform company. Every example I can think of of a company that tried to start as a platform company fails. You got to start as a technology first. When did you think about making that transition to being a platform? Like your first graphics cards were technology? There was no Cuda. There was no.
C: Yeah. What you observed is not wrong, however. Inside our company, we were always a platform company. And the reason for that is because from the very first day of our company, we had this architecture called UDA. It's the ooda of Cuda.
B: CuDA is compute unified device architecture.
C: That's right. And the reason for that is because what we've done, what we essentially did in the beginning, even though Riva 128 only had computer graphics, the architecture described accelerators of all kinds. And we would take that architecture and developers would program to it. In fact, Nvidia's first strategy, business strategy, was we were going to be a game console inside the pc. And a game console needs developers, which is the reason why Nvidia, a long time ago, one of our first employees was a developer relations person. And so it's the reason why we knew all the game developers and all the 3d developers, and we knew everything.
B: So was the original business plan to, like, sort of like to build DirectX?
C: Yeah.
B: Compete with Nintendo and Sega as, like, with PCs.
C: Original Nvidia architecture was called Direct Envy. Direct Nvidia, yeah. And DirectX was an API that made it possible for operating system to directly address hardware.
B: Yeah, but DirectX works when you started Nvidia. Right. And that's what made your strategy run.
C: For the first couple years. In 1993, we had direct Nvidia, which in 1995 became, well, DirectX came out.
A: So this is an important lesson.
C: We were always a developer oriented company.
A: The initial attempt was we will get the developers to build on direct envy, and then they'll build for our chips, and then we'll have a platform. And what played out is Microsoft already had all these developer relationships. So you learned the lesson the hard way of like, yikes, we just got to.
B: That's what Microsoft did back in the day. They're like, oh, that could be a developer platform. We'll take that. Thank you.
C: No, but they had a lot. They did it very differently, and they did a lot of things right. We did a lot of things wrong.
B: But you were competing against Microsoft in the nineties. I mean, that's like trying to compete against Nvidia today.
C: No, it's a lot different. I appreciate that, but we were nowhere near competing with them. If you look now, when Cuda came along and there was OpenGL, there was DirectX, but there's still another extension, if you will. And that extension is Cuda. That CudA extension allows a chip that got paid for running DirectX and OpenGL to create an install base for CuDA.
B: The Nvidia stress why you are so militant. And I think from our research, it really was you being militant that every Nvidia chip will run CUDA.
C: Yeah. If you're a computing platform, everything's got to be compatible. We are the only accelerator on the planet where every single accelerator is architecturally compatible with the others. None has ever existed. There are literally a couple of hundred million. Right? 250 million, 300 million installed base of active CUdA GPU is being used in the world today. And they're all architecturally compatible. How would you have a computing platform if MV 30 and MV 35 and 39 and NMV 40, they're all different at 30 years, it's all completely compatible. And so that's the only unnegotiable rule in our company. Everything else is negotiable.
B: I mean, I guess Kudo was a rebirth of UDa, but understanding this now, UDa going all the way back, it really is all the way back to all the chips you've ever.
C: Yeah, yeah, yeah. In fact, UDa goes all the way back to all of our chips today. Wow. For the record, I didn't help any of the founding CEO's that are listening. I gotta tell you, while you were asking that question, what lessons would I impart? I don't know. I mean, the characteristics of successful companies and successful CEO's I think are fairly well described. There are a whole bunch of them. I just think starting successful companies are insanely hard. It's just insanely hard. And when I see these amazing companies getting built, I have nothing but admiration and respect, because I just know that it's insanely hard. And I think that everybody did many similar things. There are some good smart things that people do, there are some dumb things that you can do, but you could do all the right smart things and still fail. You could do a whole bunch of dumb things, and I did many of them and still succeed. So obviously that's not exactly right. I think skills are the things that you can learn along the way, but at important moments, certain circumstances have to come together. And I do think that, that the market has to be one of the agents to help you succeed. It's not enough, obviously, because a lot of people still fail.
A: Do you remember any moments in Nvidia's history where you're like, oh, we made a bunch of wrong decisions, but somehow we got saved because it takes the sum of all the luck and all the skill in order to succeed. Do you remember any moments where you.
C: I should have thought that you started with rebound 120 was spot on. Revo 128. As I mentioned, the number of smart decisions we made which are smart to this day. How we design chips is exactly the same to this day because, gosh, nobody's ever done it back then. And we pulled every trick in the book in a desperation because we had no other choice. Well, guess what? That's the way things ought to be done. And now everybody does it that way, right? Everybody does it. Because why should you do things twice if you can do it once, why tape out a chip seven times? If you could tape it out one time, right? And so the most efficient, the most cost effective, the most competitive, speed is technology, right? Speed is performance. Time to market is performance. All of those things apply. So why do things twice if you could do it once? And so revo 128 made a lot of great decisions and how we spec products, how we think about market needs and lack of, how do we judge markets and all of this, man, we made some amazingly good decisions. Yeah, we were back against the wall. We only had one more shot to do it.
A: But once you pull out all the stops and you see what you're capable of, why would you put stops in?
C: Exactly. Exactly.
A: Like, let's keep stops out all the time, every time.
C: That's right.
B: Is it fair to say though, maybe on the luck side of the equation, thinking back to 1997, that that was the moment where consumers tip to really, really valuing 3d graphical performance in games?
C: Oh yeah. So for example, luck, let's talk about luck. If Carmack had decided to use acceleration, because remember, Doom was completely software rendered. And the Nvidia philosophy was that although general purpose computing is a fabulous thing, it's going to enable software and it and everything, we felt that there were applications that wouldn't be possible or it would be costly. If it wasn't accelerated, it should be accelerated. And 3d graphics was one of them, but it wasn't the only one. And it just happens to be the first one and a really great one. And I still remember the first times we met John. He was quite emphatic about using cpu's and the software renderer was really good. I mean, quite frankly, if you look at Doom, the performance of Doom was really hard to achieve. Even with accelerators at the time. If you didn't filter, if you didn't have to do bilinear filtering, it did a pretty good job.
B: The problem with doom though was you needed Carmac to program it.
C: Yeah, you needed Carmac to program it. Exactly. It was a genius piece of code, but nonetheless, software renderers did a really good job. And if he hadn't decided to go to OpenGL and accelerate for Quake, frankly, what would be the killer app that put us here? Carmack and Sweeney, both between unreal and Quake, created the first two killer applications for consumer three D. I owe them a great deal.
B: I want to come back real quick too. You said you told these stories and you're like, well, I don't know what founders can take from that. I actually do think if you look at all the big tech companies today, perhaps with the exception of Google, they did all start and understanding this now about you by addressing developers, planning to build a platform and tools for developers.
A: All of them, Apple, not Amazon.
B: Well, I guess with AWs, that's how Aws started. So I think that actually is a lesson to your point of like that won't guarantee success by any means, but that'll get you hanging around a tree if the apple falls.
C: Yeah. As many good ideas as we have, you don't have all the world's good ideas. And the benefit of having developers is you get to see a lot of good ideas. Yep. Yeah.
A: Well, as we start to drift toward the end here, we spent a lot of time on the past and I want to think about the future a little bit. I'm sure you spend a lot of time on this being on the cutting edge of AI. We're moving into an era where the productivity that software can accomplish when a person is using software can massively amplify the impact and the value that they're creating, which has to be amazing for humanity in the long run. In the short term, it's going to be inevitably bumpy as we figure out what that means. What do you think some of the solutions are as AI gets more and more powerful and better at accelerating productivity for all the displaced jobs that are going to come from it?
C: Well, first of all, we have to keep AI safe. And there's a couple of different areas of AI safety that's really important. Obviously, in robotics and self driving car, there's a whole field of AI safety. And we've dedicated ourselves to functional safety and active safety in all kinds of different areas of safety. When to apply human in the loop, when is it okay for human not to be in the loop? How do you get to a point where increasingly human doesn't have to be in the loop, but human largely in the loop? In the case of information safety, obviously bias, false information and appreciating the rights of artists and creators, that whole area deserves a lot of attention. And you've seen some of the work that we've done. Instead of scraping the Internet, we partnered with Getty and Shutterstock to create commercially fair way of applying artificial intelligence generated to the AI in the area of large language models. In the future of increasingly greater agency AI, clearly the answer is for as long as it's sensible, and I think it's going to be sensible for a long time. Is human in the loop? The ability for an AI to self learn and improve and change out in the wild in a digital form should be avoided. And we should collect data, we should carry the data, we should train the model, we should test the model, validate the model before we release it on the wild again. So human is in the loop. There are a lot of different industries that have already demonstrated how to build systems that are safe and good for humanity. Obviously, the way autopilot works for a plane and two pilot system, and then air traffic control and redundancy and diversity, and all of the basic philosophies of designing safe systems apply as well in self driving cars and so on and so forth. I think there's a lot of models of creating safe AI, and I think we need to apply them with respect to automation. My feeling is that, and we'll see, but it is more likely that AI is going to create more jobs. And in the near term, the question is, what's the definition of near term? And the reason for that is the first thing that happens with productivity is prosperity. And prosperity, when the companies get more successful, they hire more people because they want to expand into more areas. The question is, if you think about a company and say, okay, if we improve the productivity, then they need fewer people. Well, that's because the company has no more ideas. But that's not true for most companies. If you become more productive and the company becomes more profitable, usually they hire more people to expand into new areas. And so long as we believe that there are more areas to expand into, that there are more ideas in drug discovery, there are more ideas in transportation, there are more ideas in retail, there are more ideas in entertainment, that the. There's more ideas in technology. So long as we believe that there are more ideas. The prosperity of the industry, which comes from improved productivity, results in hiring more people. More ideas. Now, you go back in history, we can fairly say that today's industry is larger than the world's industries 1000 years ago. And the reason for that is because obviously humans have a lot of ideas. And I think that there's plenty of ideas yet for prosperity and plenty of ideas that can be begat from productivity improvements. But my sense is that it's likely to generate jobs. Now, obviously, net generation of jobs doesn't guarantee that any one human doesn't get fired. Okay? I mean, that's obviously true. And it's more likely that someone will lose a job to someone else, some other human that uses an AI, and not likely to an AI, but to some other human that uses an AI. I think the first thing that everybody should do is learn how to use AI so that they can augment their own productivity. And every company should augment their own productivity to be more productive so that they could have more prosperity, hire more people. And so I think jobs will change. My guess is that we'll actually have higher employment, will create more jobs. I think industries will be more productive, and many of the industries that are currently suffering from lack of labor workforce is likely to use AI to get themselves off their feet and get back to growth and prosperity. So I see it a little bit differently, but I do think that jobs will be affected, and I'd encourage everybody just to learn AI.
B: This is appropriate. There's a version of something we talk about a lot on acquired. We call it the Maritz Corollary to Moore's Law, after Mike Moritz from Sequoia.
C: Sequoia was the first investor in our company.
B: Yeah, of course.
C: Yeah.
B: The great story behind it is that when Mike was taking over for Don Valentine with Doug, he was sitting and looking at Sequoia's returns and he was looking at fund three or four, I think it was four. Maybe that had Cisco in it. He was like, how are we ever going to top that? I can't, you know, don's going to have us beat. We're never going to beat that. He thought about it and he realized that, well, as compute gets cheaper and it can access more areas of the economy because it gets cheaper and can get adopted more widely, well, then the markets that we can address should get bigger.
C: Yeah.
B: And AI, your argument is basically.
C: Exactly.
B: AI will do the same thing.
C: Exactly.
B: This cycle will do.
C: I just gave you exactly the same example that, in fact, productivity doesn't result in us doing less. Productivity usually results in us doing more. Everything we do will be easier, but we'll end up doing more because we have infinite ambition. The world has infinite ambition. So if a company is more profitable, they tend to hire more people to do more. That's true.
A: Technology is a lever, and the place where the idea falls down is that, that we would be satisfied.
B: Humans have never ending ambition.
A: No, humans will always expand and consume more energy and attempt to pursue more ideas. That has always been true of every version of our species over time.
B: Now is a great time to share something new from our friends at Blinkist. And go. One that is very appropriate to this episode.
A: Yes. So, personal story time. I, a few weeks ago was scouring the web to find Jensen's favorite business books, which was proving to be difficult. I really wanted Blinkist to make blinks of each of those books so you could all access them. And I think I found one or two in random articles, but that just wasn't enough. So finally, before I gave up as a last resort, I asked an AI chat bot, specifically Bard, to provide me a list and cite the sources of Jensen's favorite business books. And miraculously, it worked. Bard found books that Jensen had called out in public forums over the past several decades. So if you click the link in the show notes or go to blinkist.com Jensen, you can get the blinks of all five of those books, plus a few more that Jensen specifically told us about later in the episode.
B: Yes, and we also have an offer from Blinkist and Gowon that goes beyond personal learning. Blinkist has handpicked a collection of books related to the themes of this episode. So tech innovation, leadership, the dynamics of acquisitions, these books offer the mental models to adapt to a rapidly changing technology environment.
A: And just like all other episodes, Blinkist is giving acquired listeners an exclusive 50% discount on all premium content. This gives you key insights from thousands of books at your fingertips, all condensed into easy to digest summaries. And if you're a founder, a team lead, or an L and D manager, Blinkist also includes curated reading lists and progress tracking features, all overseen by a dedicated customer success manager to help your team flourish as you grow.
B: Yes. So to claim the whole free collection, unlock the 50% discount, and explore Blinkist's enterprise solution, simply visit blinkist.com Jensen and use the promo code. Jensen, Blinkist, and their parent company, go one, are truly awesome resources for your company and your teams as they develop from small startup to enterprise. Our thanks to them. And seriously, this offer is pretty awesome. Go take them up on it. We have a few lightning round questions we want to ask you, and then we have. And then we have a very funk.
C: That fast?
A: We'll open with an easy one based on all these conference rooms we see named around here. Favorite Sci-Fi book?
C: I've never read a Sci-Fi book before.
A: No?
B: Come on.
A: What's weird? The obsession with Star Trek and just.
C: Watch the tv show. Okay.
B: Favorite Sci-Fi tv series?
C: Star Trek's my favorite. Yeah, yeah. Star Trek's my favorite.
A: I saw Viger out there on the way in. That's a good conference room name.
C: Vijer is an excellent one.
A: Yeah, yeah.
B: What car is your daily driver these days? And related questions. You still have the Supra?
C: Oh, it's one of my favorite cars. And also favorite memories. You guys might not know this, but Lori and I got engaged Christmas one year and we drove back in my brand new supra and we totaled it. We were this close to the end.
A: Thank God you didn't.
C: But nonetheless, it wasn't my fault. It wasn't the Supra's fault, but it's a mark. I love it.
B: The one time when it wasn't the Supra's fault.
C: I love that car. I'm driven these days for security reasons and others, but I'm driven in the Mercedes EQs. It's a great car. Yeah. Great car. Thanks.
B: Using Nvidia technology.
C: Yeah, we're in the. We're the central computer. Yep.
A: Sweet. I know we already talked a little bit about business books, but one or two favorites that you've taken something from Clay Christensen.
C: I think the series is the best. I mean, there's just no two ways about it. And the reason for that is because it's so intuitive and so sensible. It's approachable. But I read a whole bunch of them and I read just about all of them. I really enjoyed Andy Grove's books. They're all really good.
A: Awesome. Favorite characteristic of Don Valentine's, grumpy but endearing.
C: And what he said to me the last time as he decided to invest in our company, he says, if you lose my money, I'll kill you.
B: Of course he did.
C: And then over the course of the decades, the years that followed, when something is nice written about us in Mercury News, it seems like he wrote it in a crayon. He'll say, good job done. Just write over the newspaper and just, good job done. And he mails it to me and I hope I've kept them. But anyways, you could tell he's a real sweetheart. But he cares about the companies.
B: He's a special character.
C: Yeah, he's incredible.
A: What is something that you believe today that 40 year old Jensen would have pushed back on and said, no, I disagree.
C: There's plenty of time. Yeah, there's plenty of time if you prioritize yourself properly and you make sure that you don't let outlook be the controller of your time. There's plenty of time.
B: Plenty of time in the day. Plenty of time to do anything to achieve things.
C: Just don't do everything. Prioritize your life. Make sacrifices. Don't let outlook control what you do every day. Notice I was late to our meeting. And the reason for that, by the time I looked up, I. Oh, my gosh. You know, Ben and Dave are waiting. You know, it's already. We have time yeah, exactly.
B: Didn't stop this from being a great job.
C: No, but you have to prioritize your time really carefully and don't let outlook determine that. Love that.
A: What are you afraid of? If anything?
C: I'm afraid of the same things today that I was in the very beginning of this company, which is letting the employees down. You have a lot of people who joined your company because they believe in your hopes and dreams, and they've adopted us, their hopes and dreams. And you want to be right for them, you want to be successful for them. You want them to be able to build a great life, as well as help you build a great company and be able to build a great career. You want them to have to enjoy all of that. And these days, I want them to be able to enjoy the things I've had the benefit of enjoying and all the great success I've enjoyed. I want them to be able to enjoy all of that. And so I think the greatest fear is that you let them down.
B: What point did you realize that you weren't going to have another job? That, like, this was it.
C: I just. I don't change jobs. You know? If it wasn't because of Chris and Curtis convincing me to do do Nvidia, I would still be at LSI Logic today. I'm certain of it.
A: Wow, really?
C: Yeah, yeah, I'm certain of it. I would keep doing what I'm doing. And at the time that I was there, I was completely dedicated and focused on helping LSI Logic be the best company it could be. And I was lSi Logic's best ambassador. I've got great friends to this day that I've known from LSI Logic. It's a company I loved then, I loved dearly. Today, I know exactly why I went. The revolutionary impact it had on chip design and system design and computer design. In my estimation, one of the most important companies that ever came to Silicon Valley and changed everything about how computers were made. It put me in the epicenter of some of the most important events in computer industry. It led me to meeting Chris and Curtis and Andy Bechtlescheim and John Rubinstein and some of the most important people in the world, and Ed Frank that I was with the other day. And just, I mean, the list goes on. And so lsi logic was really important to me, and I would still be there. I would. Who knows what LSi logic would have become if I were still there, right. And so that's kind of how my mind works.
B: Powering the AI of the world.
C: Yeah, exactly. I mean, I might be doing the same thing I'm doing today. Is that the sense?
B: From remembering back to part one of our series on Nvidia.
C: But until I'm fired, this is my last job. I love it.
B: I got the sense that lsi logic might have also changed your perspective and philosophy about computing, too. The sense we got from the research, was that right out of school when you first went to AMD first, right?
C: Yeah.
B: You believed that. Like kind of a version of that. Was it the Jerry Sanders? Real men have fabs, like you need to do the whole stack, like, you gotta do everything. And that lsi logic changed you.
C: What LSI logic did was realize that you can express transistors and logical gates and chip functionality in high level languages. That by raising the level of abstraction in what is now called high level design. It was coined by Harvey Jones, who's on Nvidia's board, and I met him way back in the early days of synopsis. But during that time, there was this belief that you can express chip design in high level languages, and by doing so, you could take advantage of optimizing compilers and optimization logic and tools and be a lot more productive. That logic was so sensible to me, and I was 21 years old at the time, and I wanted to pursue that vision. Frankly, that idea happened in machine learning, it happened in software programming. I want to see it happen in digital biology so that we can think about biology in a much higher level language. Probably a large language model would be the way to make it representable. That transition was so revolutionary. I thought that was the best thing ever happened to the industry, and I was really happy to be part of it. And I was at ground zero. And so I saw one industry change revolutionize another industry. And if not for LSI logic doing the work that it did synopsis shortly after, then why would the computer industry be where it is today? Yeah, it's really, really terrific. I was at the right place at the right time to see all that.
B: That's super cool.
C: Yeah.
B: And it sounded like the CEO of LSI logic put a good word in for you with Don Valentine's Day.
C: I didn't know how to write a.
A: Business plan, which it turns out is not actually important.
C: No, no, no. It turns out that making a financial forecast that nobody knows is going to be right or wrong turns out not to be that important. But the important things that a business plan probably could have teased out. I think that the art of writing a business plan ought to be much, much shorter, and it forces you to condense. What is the true problem you're trying to solve? What is the unmet need that you believe will emerge? And what is it that you're going to do that is sufficiently hard that when everybody else finds out it's a good idea, they're not going to swarm it and make you obsolete? It has to be sufficiently hard to do. There are a whole bunch of other skills that are involved in just product and positioning and pricing and go to market and all that kind of stuff. But those are skills and you can learn those things easily. The stuff that is really, really hard is the essence of what I described. I did that. Okay. But I had no idea how to write the business plan. And I was fortunate that Wolf Corrigan was so pleased with me and the work that I did. When I was at Elsa Logic, he called up Don Valentine and told, Don, invest in this kid and he's going to come your way. So I was set up for success from that moment and got us off the ground.
A: As long as you didn't lose the money.
C: I think Sequoia did. Okay, that was good. I think we probably are one of the best investments they've ever made. Have they held through today? The VC partner is still on the board. Mark Stevens. Yeah.
B: Mark Hill. Yeah.
C: All these years the two founding VC's are still on the board.
A: Sutter Hill and Sequoia.
C: Yeah. Tenchcox and Mark Stevens. I don't think that ever happens.
B: Yeah.
C: We are singular in that circumstance. I believe they've added value this whole time. Been inspiring this whole time. Gave great wisdom and great support. But they also were.
B: So they haven't killed you yet?
C: No, not yet. But they've been entertained, you know, by the company, inspired by the company and enriched by the company. And so they stayed with it. And I'm really grateful.
B: Well, in that being our final question for you, it's 20, 23, 30 years anniversary of the founding of Nvidia. If you were magically 30 years old again today in 2023 and you were going to Denny's with your two best friends, who are the two smartest people you know, and you're talking about starting a company. What are you talking about starting?
C: I wouldn't do it. I know. And the reason for that is really quite simple. Ignoring the company that we would start. First of all, I'm not exactly sure the reason why I wouldn't do it, and it goes back to why it's so hard, is building a company and building a video turned out to have been a million times harder than I expected it to be. Any of us expected it to be. And at that time, if we realized the pain and suffering and just how vulnerable you're going to feel and the challenges that you're going to endure, the embarrassment and the shame and the list of all the things that go wrong, I don't think anybody would start a company. Nobody in their right mind would do it. And I think that that's kind of the superpower of a entrepreneur. They don't know how hard it is and they only ask themselves, how hard can it be? And to this day, I trick my brain into thinking, how hard can it be? Because you have to still, when you.
A: Wake up in the morning.
C: Yeah. How hard can it be? Everything that we're doing, how hard can it be? Omniverse. How hard can it be in terms of.
B: I get the sense, though, that you're planning to retire anytime soon, though.
C: No, you're still young. I'm still young.
B: You could choose to say, like, whoa, this is too hard.
A: The trick is still working.
B: You're still. The trick is still working.
C: I'm still enjoying myself immensely and I'm adding a little bit of value, but that's really the trick of an entrepreneur. You have to get yourself to believe that it's not that hard because it's way harder than you think. And so if I go taking all of my knowledge now and I go back and I said, I'm going to endure that whole journey again, I think it's too much. It is just too much.
A: Do you have any suggestions on any kind of support system or a way to get through the emotional trauma that comes with building something like this?
C: Family and friends and all the colleagues we have here. I'm surrounded by people who've been here for 30 years. Right. Chris has been here for 30 years, and Jeff Fisher's been here 30 years. Dwight's been here 30 years. Jonah and Brian have been here 25 some years and probably longer than that. And Joe Greco has been here 30 years. I'm surrounded by these people that never one time gave up, and they never one time gave up on me. And that's the entire ball of wax. And to be able to go home and have your family be fully committed to everything that you're trying to do, and thick or thin, they're proud of you and proud of the company. You kind of need that. You need the unwavering support of people around you. You know, Jim Gaithers and the tench coxes and Mark Stevens and Harvey Jones. And all the early people of our company, the Bill Millers, they not one time gave up on the company and us. And you need that. Not kind of need that. You need that. And I'm pretty sure that almost every successful company, entrepreneurs that have gone through some difficult challenges, they had that support system around them.
B: I can only imagine how meaningful that. I mean, I know how meaningful that is in any company. But for you, given, I feel like the Nvidia journey is particularly amplified on these dimensions. Right.
C: Not normal.
B: You went through two, if not three, near death benefits, 80% plus drawdowns in the public markets. To have investors who've stuck with you from day one through that must be just like so much support.
C: Yeah, yeah. It is incredible. And you hate that any of that stuff happen. And most of it, you know, most of it is out of your control, but in a 80% fall, it's an extraordinary thing, no matter how you look at it. And I forget exactly, but I mean, we traded down at about a couple of two, $3 billion in market value for a while because of the decision we made in going into CuDA and all that work. And your belief system has to be really, really strong. You have to really, really believe it and really, really want it. Otherwise, it's just too much to endure. Because everybody's questioning you and employees aren't questioning you, but employees have questions, people outside are questioning you. And it's a little embarrassing. It's like when your stock price gets hit, it's embarrassing no matter how you think about it, and it's hard to explain. And so there's no good answers to any of that stuff. CEO's are human and companies are built of humans and these challenges are hard to endure.
B: Ben had an appropriate comment on our most recent episode on you all, where we were talking about the current situation in Nvidia. And I think you said for any other company, this would be a precarious spot to be in.
A: But for Nvidia, this is kind of old hat. You guys are familiar with these large swings in amplitude?
C: Yeah. The thing that to keep in mind is at all times what is the market opportunity that you're engaging and that informs your size? You know, I was told a long time ago that Nvidia can never be larger than a billion dollars. Obviously, it's an underestimation under imagination of the size of the opportunity. It is the case that no chip company can ever be so big. But if you're not a chip company, then why does that apply to you? And this is the extraordinary thing about technology right now is technology is a tool, and it's only so large. What's unique about our current circumstance today is that we're in the manufacturing of intelligence. We're in the manufacturing of work world. That's AI and the world of tasks, doing work, productive, generative AI work, generative, intelligent work. That market size is enormous. It's measured in trillions of. One way to think about that is, if you built a chip for a car, how many cars are there and how many chips would they consume? That's one way to think about that. However, if you built a system that, whenever needed, assisted in the driving of the car, what's the value of a autonomous chauffeur every now and then? Now the market, obviously the problem becomes much larger. The opportunity becomes larger. What would it be like if we were to magically conjure up a chauffeur for everybody who has a car? And how big is that market? And obviously that's a much, much larger market. The technology industry is at the what we discovered, what Nvidia has discovered, and what some of it discovered is that by separating ourselves from being a chip company, but building on top of a chip and you're not an ag company, the market opportunity has grown by probably 1000 times. Don't be surprised if technology companies become much larger in the future, because what you produce is something very different. That's the way to think about, you know, how large can your opportunity, how large can you be? That has everything to do with the size of the opportunity.
A: Yep. Well, Jensen, thank you so much.
C: Thank you.
A: Ooh, David, that was awesome.
B: So fun.
A: Well, listeners, we want to tell you that you should totally sign up for our email list. Of course, it is notifications when we drop a new email, but we've added something new. We're including little tidbits that we learn after releasing the episode, including listener corrections. And we also have been sort of teasing what the next episode will be. So if you want to play the little guessing game along with the rest of the acquired community, sign up at acquired FM email. Our huge thank you to Blinkist, Statsig and Crusoe. All the links in the show notes are available. To learn more and get the exclusive offers for the acquired community from each of them, you should check out ACQ two, which is available at any podcast player. As these main acquired episodes get longer and come out, you know, once a month instead of every couple weeks, it's a little bit more of a rarity these days.
B: We've been up leveling our production process, and that takes time.
A: Yes, ACQ two has become the place to get more from David and I, and we've just got some awesome episodes coming up that we are excited about. If you want to come deeper into the acquired kitchen, become an LP. Acquired FM LP. Once every couple months or so, we'll be doing a call with all of you on Zoom just for LP's to get the inside scoop of what's going on in acquired land and get to know David and I a little bit better. And once a season, you'll get to help us pick a future episode. So that's acquired FM LP. Anyone should join the slack. Acquired FM Slack. God, we've got a lot of things now, David.
B: I know. The hamburger bar on our website is expanding.
A: Expanding. I know that's how you know we're becoming enterprise. We have a mega menu, a menu of menus, if you will.
B: What is the acquired solution that we can sell?
A: That's true.
B: We gotta find that.
A: All right. With that, listeners, acquire FM Slack to join the slack and discuss this episode. Acquired FM store to get some of that sweet merch that everyone is talking about. And with that, listeners, we will see you next time.
B: We'll see you next time.
C: Who got the truth?
A: Is it you?
C: Is it you? Is it you? Who got the truth now?
